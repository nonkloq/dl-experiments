{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d4bc23b9-6fa2-43c2-8dd1-7558f881c36b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch as th \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "527f96e0-6c00-4b21-8cc5-15946714f594",
   "metadata": {},
   "source": [
    "### Toy Data\n",
    "\n",
    "Simple math expression with variables and their results\n",
    "```txt\n",
    "EXPR -> $k - ( k / a - e );k=8.41,e=9.85,a=5.48! \n",
    "RES -> [16.73]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7e0a257d-5eb9-4d3a-bb38-8055e7b79ecc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([13, 66])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from simple_expressions import SimpleExpression, expr_vocabulary, PADDING_TOKEN_ID, UNKNOWN_CHAR_ID, START_OF_ANSWER, encode_expression, decode_expression\n",
    "\n",
    "class ExpSentence(SimpleExpression):\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self.vocab = expr_vocabulary\n",
    "        \n",
    "    def sample(self, batch_size: int):\n",
    "        expression, target = super().sample(batch_size)\n",
    "        full_sentence = []\n",
    "        answer_break_points = []\n",
    "        for i in range(batch_size):\n",
    "            full_sentence.append(expression[i]  + target[i])\n",
    "            answer_break_points.append(len(expression[i]))\n",
    "        return full_sentence, answer_break_points\n",
    "\n",
    "    def create_training_batch(self, context_window: int, batch_size: int):\n",
    "        sentences, break_points = self.sample(batch_size) \n",
    "\n",
    "        encoded_sentences = []\n",
    "        for i in range(len(sentences)):\n",
    "            # clipping longer strings\n",
    "            if break_points[i] > context_window:\n",
    "                clip_size = break_points[i] - context_window\n",
    "                sentences[i] = sentences[i][clip_size:]\n",
    "                break_points[i] = context_window\n",
    "                assert sentences[i][context_window] == START_OF_ANSWER, f'\"{sentences[i]}\"'\n",
    "                \n",
    "            left_pad = context_window - break_points[i]\n",
    "            sent_enc = []\n",
    "            for _ in range(left_pad):\n",
    "                sent_enc.append(PADDING_TOKEN_ID)\n",
    "\n",
    "            for x in sentences[i]:\n",
    "                sent_enc.append(self.vocab.get(x,UNKNOWN_CHAR_ID))\n",
    "            encoded_sentences.append(sent_enc)\n",
    "        # shift each setences by one after '[', [max_expression_size+1:] is the context window \n",
    "        # and '[' will be the first attention query\n",
    "        batches = []        \n",
    "        for encoded_sentence in encoded_sentences:\n",
    "            for i in range(len(encoded_sentence) - context_window-1):\n",
    "                batches.append(encoded_sentence[i:i+ context_window+2])\n",
    "\n",
    "        # safety check\n",
    "        # starts with  '>' '['\n",
    "        assert batches[0][-2] == self.vocab[START_OF_ANSWER]\n",
    "        for b in batches:\n",
    "            assert b[-1] != self.vocab[START_OF_ANSWER], f\"{b}\"\n",
    "            \n",
    "        return th.tensor(batches, dtype=th.long)\n",
    "                \n",
    "                \n",
    "sampler = ExpSentence(3, (1, 3), (-10, 10), 2, 0.5)\n",
    "batch = sampler.create_training_batch(64, 2)\n",
    "batch.shape # [Batch, cntxt+1 + 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d4b38b3-24ef-47df-b638-a9a1227cf945",
   "metadata": {},
   "source": [
    "# Additive Attention\n",
    "\n",
    "Attending to previous tokens using the -1 as query\n",
    "\n",
    "using the additive attention\n",
    "$$\n",
    "\\alpha(q,k) = w_v^T tanh(W_q q + W_k k) \\in R\n",
    "$$\n",
    "and attention pooling\n",
    "$$\n",
    "Attention(q,\\mathcal{D}) = \\sum_{i=1}^m \\alpha (q, k_i)v_i,\n",
    "$$\n",
    "but v = k."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "39e72b6c-ad17-4990-8560-f6da40d8996e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AttentionPool(th.nn.Module):\n",
    "    def __init__(self,input_dim: int, hidden_dim: int):\n",
    "        super().__init__()\n",
    "\n",
    "        self.query = th.nn.Linear(in_features=input_dim, out_features=hidden_dim)\n",
    "        self.key = th.nn.Linear(in_features=input_dim, out_features=hidden_dim)\n",
    "\n",
    "        self.weight = th.nn.Linear(in_features=hidden_dim, out_features=1)\n",
    "\n",
    "    def forward(self, q: th.Tensor, v: th.Tensor, pad_mask: th.Tensor,):\n",
    "        \"\"\" If key values aren't provided, will use the v as both key and value \"\"\"\n",
    "        # q: [B, n]\n",
    "        # v: [B, m, n] where D: [m, n] \n",
    "        query_out = self.query(q).unsqueeze(1) # [B,1,k] when single query \n",
    "        keys_out = self.key(v) # [B, m, k]\n",
    "        \n",
    "        # additive attention by broad casting\n",
    "        additive_attention = th.tanh(query_out + keys_out)\n",
    "\n",
    "        e = self.weight(additive_attention).squeeze(-1) # [B, m]\n",
    "        # for softmax calculation to ignore the padded fields, we need to set them as -inf\n",
    "        # https://juditacs.github.io/2018/12/27/masked-attention.html\n",
    "        e = e.masked_fill(pad_mask,  float('-inf'))\n",
    "\n",
    "        alpha = th.softmax(e, dim=-1).unsqueeze(-1) # [B, m, 1] \n",
    "        attention_pool = (alpha*v).sum(dim=1) # [B, n]\n",
    "        return attention_pool\n",
    "\n",
    "\n",
    "with th.no_grad():\n",
    "    batch = 10\n",
    "    contxt_window = 32\n",
    "    embedding_size = 5\n",
    "    attn_pool = AttentionPool(input_dim=embedding_size, hidden_dim=3)\n",
    "    # setting right half as valid tokens and left as paddings\n",
    "    pad_mask = th.zeros(batch, contxt_window)\n",
    "    pad_mask[:, contxt_window//2:] = 1 \n",
    "    pad_mask = (pad_mask==0)\n",
    "    \n",
    "    que = th.randn(batch, embedding_size)\n",
    "    val = th.randn(batch, contxt_window, embedding_size)\n",
    "    out = attn_pool(que, val, pad_mask)\n",
    "    assert out.shape == (batch, embedding_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb3d2d2e-25eb-4a5c-a0db-f12d44b9d9ee",
   "metadata": {},
   "source": [
    "# Self-Attention\n",
    "\n",
    "Using the input and weights \\(Q, K, V\\) to get the query, key & value vectors\n",
    "\n",
    "Using additive attention will require too much memory due to the (Wq + Wk) operation which requires broadcasting the matrix to (B, seq, seq, n), so using simple dot production attention (we already have parameters to produce q,k,v using embeddings)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "91f01c43-65b1-4675-8e95-02cdbee70530",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SelfAttention(th.nn.Module):\n",
    "    def __init__(self,input_dim: int, output_dim: int):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.query = th.nn.Linear(in_features=input_dim, out_features=output_dim)\n",
    "        self.key = th.nn.Linear(in_features=input_dim, out_features=output_dim)\n",
    "        self.value = th.nn.Linear(in_features=input_dim, out_features=output_dim)\n",
    "\n",
    "    def forward(self, x: th.Tensor, pad_mask: th.Tensor):\n",
    "        # x: [B, m, n]\n",
    "\n",
    "        # All [B, m, k] and k is the out_dim\n",
    "        query = self.query(x) \n",
    "        keys = self.key(x)\n",
    "        vals = self.value(x)\n",
    "\n",
    "        # [B. m, m]\n",
    "        e = query @ keys.mT \n",
    "        # each row contains q_i^T k_1, ... q_i^T k_m\n",
    "        # masking the entier row will lead to all nans\n",
    "        # so first lets mask the padded columns with -inf [-inf, -inf, ..., q_i^T,k_m]\n",
    "        # making pad_mask to [B, 1, seq] to apply mask on each row\n",
    "        e = e.masked_fill(pad_mask.unsqueeze(1),  float('-inf'))\n",
    "        \n",
    "        alpha = th.softmax(e, dim=-1) # [B, m, m]\n",
    "        # each row has scores for [(qi, k1), ... ,(qi, km)]\n",
    "        # each row in vals, v_i is the value vector\n",
    "        # \\sum_i^M (q1, ki) * v_i1, so the row i contains \n",
    "        # attn for query_i with all keys and first components of all val vectors\n",
    "        # each row is sum of the weighted values vectors\n",
    "        # scores (1, m) \\cdot values (m, k) \n",
    "        attention_pool = alpha @ vals # [B, m, k]\n",
    "\n",
    "        # now we need to take care of the padding entries\n",
    "        attention_pool = attention_pool * (~pad_mask[...,None])\n",
    "        return attention_pool\n",
    "\n",
    "\n",
    "with th.no_grad():\n",
    "    batch = 10\n",
    "    contxt_window = 32\n",
    "    embedding_size = 5\n",
    "    out_dim = 3\n",
    "    sattn = SelfAttention(input_dim=embedding_size, output_dim=out_dim)\n",
    "    # setting right half as valid tokens and left as paddings\n",
    "    pad_mask = th.zeros(batch, contxt_window)\n",
    "    pad_mask[:, contxt_window//2:] = 1 \n",
    "    pad_mask = (pad_mask==0)\n",
    "    \n",
    "    x = th.randn(batch, contxt_window, embedding_size)\n",
    "    out = sattn(x,pad_mask)\n",
    "    assert out.shape == (batch, contxt_window, out_dim)\n",
    "    # left half full of zeros, right half full of values\n",
    "    assert out[:,:16,:].sum() == 0\n",
    "    assert abs(out[:,16:,:].sum()) >= 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcd9995f-ba98-48a5-970f-1f2f7de2d082",
   "metadata": {},
   "source": [
    "# Multihead attention\n",
    "\n",
    "h: no. heads \n",
    "d: input dimension \n",
    "\n",
    "each Q,K,V $\\in  R^{n \\times d/h}$, outputs get concatenated and x added back for residual connections, finally layernorm -> feedfroward -> non linearity (using relu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f4ac4db0-bea6-4eec-a9ac-a6436877592a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadAttentionBlock(th.nn.Module):\n",
    "    def __init__(self, in_dim: int, out_dim: int, heads: int):\n",
    "        assert in_dim % heads == 0, f\"Uneven outdim and heads {in_dim} % {heads} != 0\"\n",
    "        super().__init__()\n",
    "\n",
    "        self.num_heads = heads\n",
    "        self.head_dim = in_dim // heads\n",
    "        self._sf_scalar = self.head_dim ** 0.5\n",
    "        # same matrix produce q,k,v\n",
    "        self.qkv = th.nn.ModuleList([th.nn.Linear(in_features=in_dim, out_features=self.head_dim*3) for _ in range(heads)])\n",
    "\n",
    "        self.lnorm = th.nn.LayerNorm(in_dim)\n",
    "        self.feed_forward = th.nn.Linear(in_features=in_dim, out_features=out_dim)\n",
    "    \n",
    "    def _dot_product_self_attention(self, head: int, x: th.Tensor, pad_mask: th.Tensor):\n",
    "        B, T, _ = x.shape\n",
    "        qkv = self.qkv[head](x) \n",
    "        \n",
    "        query, keys, vals = qkv.chunk(3, dim=-1)\n",
    "        \n",
    "        # [B. m, m]\n",
    "        e = query @ keys.mT\n",
    "        # mask the scores for padded tokens\n",
    "        \n",
    "        e = e.masked_fill( pad_mask.unsqueeze(1),  float('-inf'))\n",
    "        # using scalled dot product attention \n",
    "        alpha = th.softmax(e/ self._sf_scalar, dim=-1) # [B, m, m]\n",
    "        attention_pool = alpha @ vals # [B, m, d/h]\n",
    "        attention_pool = attention_pool * (~pad_mask[...,None])\n",
    "        return attention_pool\n",
    "\n",
    "    def forward(self, x: th.Tensor, pad_mask: th.Tensor):\n",
    "        # x: [B, m, d]\n",
    "        # attention: [B, m, d] where d is the concatenated d/h attention pools\n",
    "        attention = th.concat([self._dot_product_self_attention(head=i, x=x, pad_mask=pad_mask) for i in range(self.num_heads)],dim=-1)\n",
    "        # for padding tokens the the entries in x will have 0 vectors\n",
    "        resid_norm = self.lnorm(attention + x)\n",
    "        logits = self.feed_forward(resid_norm) * (~pad_mask[...,None])\n",
    "\n",
    "        return th.relu(logits)\n",
    "with th.no_grad():\n",
    "    batch = 10\n",
    "    contxt_window = 32\n",
    "    embedding_size = 8\n",
    "    out_dim = 3\n",
    "    mattn = MultiHeadAttentionBlock(in_dim=embedding_size, out_dim=out_dim,heads=2)\n",
    "    # setting right half as valid tokens and left as paddings\n",
    "    pad_mask = th.zeros(batch, contxt_window)\n",
    "    pad_mask[:, contxt_window//2:] = 1 \n",
    "    pad_mask = (pad_mask==0)\n",
    "    \n",
    "    x = th.randn(batch, contxt_window, embedding_size)\n",
    "    # make the left side 0 embedding vectors\n",
    "    x[:, :contxt_window//2, :] = 0 \n",
    "    \n",
    "    out = mattn(x,pad_mask)\n",
    "    assert out.shape == (batch, contxt_window, out_dim)\n",
    "        # left half full of zeros, right half full of values\n",
    "    assert out[:,:16,:].sum() == 0\n",
    "    assert abs(out[:,16:,:].sum()) >= 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0192d8f0-93f3-44cb-a36d-3144e2598af4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModelWithAttention(th.nn.Module):\n",
    "    def __init__(self, vocab_size: int, embedding_dim: int, hidden_dim: int, padding_idx: int, ctxt_size: int, heads:int):\n",
    "        super().__init__()\n",
    "        self._padding_id = padding_idx\n",
    "        # # initialize embeddings as on hot encoded vector + small noise\n",
    "        # noisy_onehot = th.eye(vocab_size) + (th.randn(vocab_size, vocab_size) - 0.5) * 0.033\n",
    "        self.embeddings = th.nn.Embedding(num_embeddings=vocab_size, embedding_dim=embedding_dim,padding_idx=padding_idx) #.from_pretrained(noisy_onehot, padding_idx=padding_idx)\n",
    "        self.pos_embd = th.nn.Embedding(num_embeddings=ctxt_size+1, embedding_dim=embedding_dim, padding_idx=0)\n",
    "        \n",
    "        self.attn1 = MultiHeadAttentionBlock(embedding_dim, hidden_dim, heads)\n",
    "        self.attn2 = MultiHeadAttentionBlock(hidden_dim, hidden_dim, heads)\n",
    "        \n",
    "        self.fc = th.nn.Linear(hidden_dim, vocab_size)\n",
    "        \n",
    "    def forward(self, x: th.Tensor):\n",
    "        # x: [B, seq]\n",
    "        x_embd = self.embeddings(x) # {B, seq, n]\n",
    "        pad_mask = (x == self._padding_id)\n",
    "        # [0,0,0,0,1,2,3,4..]\n",
    "        token_positions = (~pad_mask).cumsum(dim=1)\n",
    "        pos_embd = self.pos_embd(token_positions)\n",
    "        \n",
    "        x_embd += pos_embd\n",
    "        \n",
    "        attn1 = self.attn1(x_embd, pad_mask) # [B, seq, n]\n",
    "        attn_out = self.attn2(attn1, pad_mask).sum(dim=1) # [B, n]\n",
    "        return self.fc(attn_out)\n",
    "        \n",
    "with th.no_grad():\n",
    "    model = ModelWithAttention(vocab_size=10, embedding_dim=12,hidden_dim=4, padding_idx=0,ctxt_size=32, heads=4)\n",
    "    x = th.randint(0, 10, (8, 32))\n",
    "    logits = model(x)\n",
    "    assert logits.shape == (8, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1748d285-a785-49d1-ad6c-ed5adb6427cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_vars = 3\n",
    "expr_range = (2, 5)\n",
    "number_range = (-10, 10)\n",
    "float_round = 2\n",
    "sampler = ExpSentence(n_vars, expr_range, number_range, float_round, 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "126e59aa-290f-416d-952d-a218bb893474",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total: 130,486\n",
      "Trainable: 130,486\n",
      "Model size: 0.498 MB\n"
     ]
    }
   ],
   "source": [
    "embedding_dim = 64\n",
    "hidden_dim = 128\n",
    "context_window = 512 # maximum tokens that we can fit in the context\n",
    "heads = 4\n",
    "\n",
    "\n",
    "calc = ModelWithAttention(vocab_size=len(sampler.vocab), embedding_dim=embedding_dim,hidden_dim=hidden_dim, padding_idx=PADDING_TOKEN_ID,ctxt_size=context_window, heads=heads)\n",
    "\n",
    "# Total parameters\n",
    "total_params = sum(p.numel() for p in calc.parameters())\n",
    "\n",
    "# Trainable parameters only\n",
    "trainable_params = sum(p.numel() for p in calc.parameters() if p.requires_grad)\n",
    "\n",
    "print(f\"Total: {total_params:,}\")\n",
    "print(f\"Trainable: {trainable_params:,}\")\n",
    "\n",
    "param_size = 0\n",
    "for param in calc.parameters():\n",
    "    param_size += param.nelement() * param.element_size()\n",
    "    \n",
    "buffer_size = 0\n",
    "for buffer in calc.buffers():\n",
    "    buffer_size += buffer.nelement() * buffer.element_size()\n",
    "\n",
    "size_all_mb = (param_size + buffer_size) / 1024**2\n",
    "print(f\"Model size: {size_all_mb:.3f} MB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ddc06bc0-d0cf-427c-ae27-7bb9cd5cf556",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7e3a288929e844fa86960568e03c925c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training Epochs:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6fcfc1842234422195683eecfaf321b5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch #1:   0%|          | 0/32 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c6ca41dbf3394b169aaa623ef3b84e6e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch #2:   0%|          | 0/32 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4dcdda7fdcff4b5bb76701623c3acebe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch #3:   0%|          | 0/32 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "27f42b538ef345f49808ff346e7aa903",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch #4:   0%|          | 0/32 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d80dd315d94e47d3b4332e06b2bcb661",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch #5:   0%|          | 0/32 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c013d50f866f4ffcb91de8c913ef1daf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch #6:   0%|          | 0/32 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b85b729a8d784036b9b73e757ac1deb2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch #7:   0%|          | 0/32 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d5520ef4d525424bb2f56d1a3bfba9e3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch #8:   0%|          | 0/32 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3ac339f8858746f4bdafe6900a11d8cc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch #9:   0%|          | 0/32 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fd7ca3a9dac84ebb97560655433ca7c4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch #10:   0%|          | 0/32 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "eta = 0.001\n",
    "\n",
    "epochs = 10\n",
    "batch_size = 128\n",
    "batches_per_epoch = 32\n",
    "\n",
    "criterion = th.nn.CrossEntropyLoss(ignore_index=PADDING_TOKEN_ID)\n",
    "optimizer = th.optim.Adam(calc.parameters(), lr=eta)\n",
    "\n",
    "losses = []\n",
    "for epoch in tqdm(range(epochs), desc=\"Training Epochs\"):\n",
    "    batch_bar = tqdm(range(batches_per_epoch), desc=f\"Epoch #{epoch+1}\", leave=False)\n",
    "    for i in batch_bar:\n",
    "    \n",
    "        tgt = sampler.create_training_batch(batch_size, context_window)\n",
    "\n",
    "        # past sequence, next output\n",
    "        tgt_input = tgt[:, :-1]  \n",
    "        tgt_output = tgt[:, -1]\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        logits = calc(tgt_input)\n",
    "        \n",
    "        loss = criterion(\n",
    "            logits.reshape(-1, logits.size(-1)),\n",
    "            tgt_output\n",
    "        )\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        loss_val = loss.item()\n",
    "        losses.append(loss_val)\n",
    "        batch_bar.set_postfix(loss=f\"{loss_val:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b197c9bb-323e-4c04-a7d7-add7e9447e76",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "updates = list(range(1, len(losses)+1))\n",
    "plt.figure()\n",
    "plt.plot(updates, losses)\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.title(\"Training Loss\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f1037e08-e6a6-4546-8ea5-4524c39cc257",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample(\n",
    "    calc,\n",
    "    expr: str,\n",
    "    max_len: int = 10,\n",
    "    greedy: bool = True,\n",
    "):\n",
    "    expr_len = len(expr)\n",
    "\n",
    "    expr = [encode_expression(expr)]\n",
    "    expr[0].append( sampler.vocab[START_OF_ANSWER] )\n",
    "\n",
    "    with th.no_grad():\n",
    "          \n",
    "        for _ in range(max_len):\n",
    "            encodings = th.tensor(expr)\n",
    "            logits = calc(encodings)\n",
    "            # logits: [B, 1, vocab]\n",
    "            logits = logits.squeeze(1)\n",
    "    \n",
    "            if greedy:\n",
    "                next_token = logits.argmax(dim=-1)\n",
    "            else:\n",
    "                probs = th.softmax(logits, dim=-1)\n",
    "                next_token = th.multinomial(probs, num_samples=1).squeeze(1)\n",
    "    \n",
    "            expr[0].append(next_token.item())\n",
    "    \n",
    "            # early stop if all finished\n",
    "            if (next_token == sampler.vocab[']']).all():\n",
    "                break\n",
    "    \n",
    "    return expr[0][expr_len:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7f4bb578-b964-4685-822e-29472c9304e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "$( f / ( v - f ) );v=-7.42,f=-8.55! = [-7.57]\n",
      "Calc = [-.877]\n",
      "$( n / x - i );i=5.74,n=-0.77,x=-2.95! = [-5.48]\n",
      "Calc = [.88]\n",
      "$( s ) / ( p / z );s=-7.01,z=1.63,p=-9.11! = [1.25]\n",
      "Calc = [0.0]\n",
      "$( q ) + d - z;z=1.55,q=-5.63,d=-8.53! = [-15.71]\n",
      "Calc = [.55]\n",
      "$d - u - y;u=-2.7,y=-3.78,d=-0.12! = [6.36]\n",
      "Calc = [1.8]\n",
      "$( u + ( z * d ) );z=4.11,u=6.18,d=0.49! = [8.19]\n",
      "Calc = [--1.44]\n",
      "$w + j * ( w / ( j * j ) );j=-3.35,w=8.71! = [6.11]\n",
      "Calc = [-----.222.\n",
      "$( b ) / o - l;o=-9.1,b=4.94,l=-4.25! = [3.71]\n",
      "Calc = [-1.8]\n",
      "$( l ) * r - ( l + ( r - z ) );z=4.28,r=-0.08,l=-4.93! = [9.68]\n",
      "Calc = [1.4]\n",
      "$x * c - ( c ) * y;c=1.23,y=5.25,x=-2.04! = [-8.97]\n",
      "Calc = [-.444]\n"
     ]
    }
   ],
   "source": [
    "for expr_sen, bp in zip(*sampler.sample(10)):\n",
    "    expr, ans = expr_sen[:bp], expr_sen[bp:]\n",
    "    result = sample(calc, expr, greedy=True)\n",
    "    predict = ''.join(decode_expression(result))\n",
    "    print(f\"{expr} = {ans}\\nCalc = {predict}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlpr (venv)",
   "language": "python",
   "name": "mlpr"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
