{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d4bc23b9-6fa2-43c2-8dd1-7558f881c36b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch as th \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "527f96e0-6c00-4b21-8cc5-15946714f594",
   "metadata": {},
   "source": [
    "### Toy Data\n",
    "\n",
    "Simple math expression with variables and their results\n",
    "```txt\n",
    "EXPR -> $k - ( k / a - e );k=8.41,e=9.85,a=5.48! \n",
    "RES -> [16.73]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7e0a257d-5eb9-4d3a-bb38-8055e7b79ecc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([11, 66])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from simple_expressions import SimpleExpression, expr_vocabulary, PADDING_TOKEN_ID, UNKNOWN_CHAR_ID, START_OF_ANSWER, encode_expression, decode_expression\n",
    "\n",
    "class ExpSentence(SimpleExpression):\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self.vocab = expr_vocabulary\n",
    "        \n",
    "    def sample(self, batch_size: int):\n",
    "        expression, target = super().sample(batch_size)\n",
    "        full_sentence = []\n",
    "        answer_break_points = []\n",
    "        for i in range(batch_size):\n",
    "            full_sentence.append(expression[i]  + target[i])\n",
    "            answer_break_points.append(len(expression[i]))\n",
    "        return full_sentence, answer_break_points\n",
    "\n",
    "    def create_training_batch(self, context_window: int, batch_size: int):\n",
    "        sentences, break_points = self.sample(batch_size) \n",
    "\n",
    "        encoded_sentences = []\n",
    "        for i in range(len(sentences)):\n",
    "            # clipping longer strings\n",
    "            if break_points[i] > context_window:\n",
    "                clip_size = break_points[i] - context_window\n",
    "                sentences[i] = sentences[i][clip_size:]\n",
    "                break_points[i] = context_window\n",
    "                assert sentences[i][context_window] == START_OF_ANSWER, f'\"{sentences[i]}\"'\n",
    "                \n",
    "            left_pad = context_window - break_points[i]\n",
    "            sent_enc = []\n",
    "            for _ in range(left_pad):\n",
    "                sent_enc.append(PADDING_TOKEN_ID)\n",
    "\n",
    "            for x in sentences[i]:\n",
    "                sent_enc.append(self.vocab.get(x,UNKNOWN_CHAR_ID))\n",
    "            encoded_sentences.append(sent_enc)\n",
    "        # shift each setences by one after '[', [max_expression_size+1:] is the context window \n",
    "        # and '[' will be the first attention query\n",
    "        batches = []        \n",
    "        for encoded_sentence in encoded_sentences:\n",
    "            for i in range(len(encoded_sentence) - context_window-1):\n",
    "                batches.append(encoded_sentence[i:i+ context_window+2])\n",
    "\n",
    "        # safety check\n",
    "        # starts with  '>' '['\n",
    "        assert batches[0][-2] == self.vocab[START_OF_ANSWER]\n",
    "        for b in batches:\n",
    "            assert b[-1] != self.vocab[START_OF_ANSWER], f\"{b}\"\n",
    "            \n",
    "        return th.tensor(batches, dtype=th.long)\n",
    "                \n",
    "                \n",
    "sampler = ExpSentence(3, (1, 3), (-10, 10), 2, 0.5)\n",
    "batch = sampler.create_training_batch(64, 2)\n",
    "batch.shape # [Batch, cntxt+1 + 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d4b38b3-24ef-47df-b638-a9a1227cf945",
   "metadata": {},
   "source": [
    "# Additive Attention\n",
    "\n",
    "Attending to previous tokens using the -1 as query\n",
    "\n",
    "using the additive attention\n",
    "$$\n",
    "\\alpha(q,k) = w_v^T tanh(W_q q + W_k k) \\in R\n",
    "$$\n",
    "and attention pooling\n",
    "$$\n",
    "Attention(q,\\mathcal{D}) = \\sum_{i=1}^m \\alpha (q, k_i)v_i,\n",
    "$$\n",
    "but v = k."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "39e72b6c-ad17-4990-8560-f6da40d8996e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AttentionPool(th.nn.Module):\n",
    "    def __init__(self,input_dim: int, hidden_dim: int):\n",
    "        super().__init__()\n",
    "\n",
    "        self.query = th.nn.Linear(in_features=input_dim, out_features=hidden_dim)\n",
    "        self.key = th.nn.Linear(in_features=input_dim, out_features=hidden_dim)\n",
    "\n",
    "        self.weight = th.nn.Linear(in_features=hidden_dim, out_features=1)\n",
    "\n",
    "    def forward(self, q: th.Tensor, v: th.Tensor, pad_mask: th.Tensor,):\n",
    "        \"\"\" If key values aren't provided, will use the v as both key and value \"\"\"\n",
    "        # q: [B, n]\n",
    "        # v: [B, m, n] where D: [m, n] \n",
    "        query_out = self.query(q).unsqueeze(1) # [B,1,k] when single query \n",
    "        keys_out = self.key(v) # [B, m, k]\n",
    "        \n",
    "        # additive attention by broad casting\n",
    "        additive_attention = th.tanh(query_out + keys_out)\n",
    "\n",
    "        e = self.weight(additive_attention).squeeze(-1) # [B, m]\n",
    "        # for softmax calculation to ignore the padded fields, we need to set them as -inf\n",
    "        # https://juditacs.github.io/2018/12/27/masked-attention.html\n",
    "        e = e.masked_fill(pad_mask,  float('-inf'))\n",
    "\n",
    "        alpha = th.softmax(e, dim=-1).unsqueeze(-1) # [B, m, 1] \n",
    "        attention_pool = (alpha*v).sum(dim=1) # [B, n]\n",
    "        return attention_pool\n",
    "\n",
    "\n",
    "with th.no_grad():\n",
    "    batch = 10\n",
    "    contxt_window = 32\n",
    "    embedding_size = 5\n",
    "    attn_pool = AttentionPool(input_dim=embedding_size, hidden_dim=3)\n",
    "    # setting right half as valid tokens and left as paddings\n",
    "    pad_mask = th.zeros(batch, contxt_window)\n",
    "    pad_mask[:, contxt_window//2:] = 1 \n",
    "    pad_mask = (pad_mask==0)\n",
    "    \n",
    "    que = th.randn(batch, embedding_size)\n",
    "    val = th.randn(batch, contxt_window, embedding_size)\n",
    "    out = attn_pool(que, val, pad_mask)\n",
    "    assert out.shape == (batch, embedding_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb3d2d2e-25eb-4a5c-a0db-f12d44b9d9ee",
   "metadata": {},
   "source": [
    "# Self-Attention\n",
    "\n",
    "Using the input and weights \\(Q, K, V\\) to get the query, key & value vectors\n",
    "\n",
    "Using additive attention will require too much memory due to the (Wq + Wk) operation which requires broadcasting the matrix to (B, seq, seq, n), so using simple dot production attention (we already have parameters to produce q,k,v using embeddings)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "91f01c43-65b1-4675-8e95-02cdbee70530",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SelfAttention(th.nn.Module):\n",
    "    def __init__(self,input_dim: int, output_dim: int):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.query = th.nn.Linear(in_features=input_dim, out_features=output_dim)\n",
    "        self.key = th.nn.Linear(in_features=input_dim, out_features=output_dim)\n",
    "        self.value = th.nn.Linear(in_features=input_dim, out_features=output_dim)\n",
    "\n",
    "    def forward(self, x: th.Tensor, pad_mask: th.Tensor):\n",
    "        # x: [B, m, n]\n",
    "\n",
    "        # All [B, m, k] and k is the out_dim\n",
    "        query = self.query(x) \n",
    "        keys = self.key(x)\n",
    "        vals = self.value(x)\n",
    "\n",
    "        # [B. m, m]\n",
    "        e = query @ keys.mT \n",
    "        # each row contains q_i^T k_1, ... q_i^T k_m\n",
    "        # masking the entier row will lead to all nans\n",
    "        # so first lets mask the padded columns with -inf [-inf, -inf, ..., q_i^T,k_m]\n",
    "        # making pad_mask to [B, 1, seq] to apply mask on each row\n",
    "        e = e.masked_fill(pad_mask.unsqueeze(1),  float('-inf'))\n",
    "        \n",
    "        alpha = th.softmax(e, dim=-1) # [B, m, m]\n",
    "        # each row has scores for [(qi, k1), ... ,(qi, km)]\n",
    "        # each row in vals, v_i is the value vector\n",
    "        # \\sum_i^M (q1, ki) * v_i1, so the row i contains \n",
    "        # attn for query_i with all keys and first components of all val vectors\n",
    "        # each row is sum of the weighted values vectors\n",
    "        # scores (1, m) \\cdot values (m, k) \n",
    "        attention_pool = alpha @ vals # [B, m, k]\n",
    "\n",
    "        # now we need to take care of the padding entries\n",
    "        attention_pool = attention_pool * (~pad_mask[...,None])\n",
    "        return attention_pool\n",
    "\n",
    "\n",
    "with th.no_grad():\n",
    "    batch = 10\n",
    "    contxt_window = 32\n",
    "    embedding_size = 5\n",
    "    out_dim = 3\n",
    "    sattn = SelfAttention(input_dim=embedding_size, output_dim=out_dim)\n",
    "    # setting right half as valid tokens and left as paddings\n",
    "    pad_mask = th.zeros(batch, contxt_window)\n",
    "    pad_mask[:, contxt_window//2:] = 1 \n",
    "    pad_mask = (pad_mask==0)\n",
    "    \n",
    "    x = th.randn(batch, contxt_window, embedding_size)\n",
    "    out = sattn(x,pad_mask)\n",
    "    assert out.shape == (batch, contxt_window, out_dim)\n",
    "    # left half full of zeros, right half full of values\n",
    "    assert out[:,:16,:].sum() == 0\n",
    "    assert abs(out[:,16:,:].sum()) >= 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcd9995f-ba98-48a5-970f-1f2f7de2d082",
   "metadata": {},
   "source": [
    "# Multihead attention\n",
    "\n",
    "h: no. heads \n",
    "d: input dimension \n",
    "\n",
    "each Q,K,V $\\in  R^{n \\times d/h}$, outputs get concatenated and x added back for residual connections, finally layernorm -> feedfroward -> non linearity (using relu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f4ac4db0-bea6-4eec-a9ac-a6436877592a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadAttentionBlock(th.nn.Module):\n",
    "    def __init__(self, in_dim: int, out_dim: int, heads: int):\n",
    "        assert in_dim % heads == 0, f\"Uneven outdim and heads {in_dim} % {heads} != 0\"\n",
    "        super().__init__()\n",
    "\n",
    "        self.num_heads = heads\n",
    "        self.head_dim = in_dim // heads\n",
    "        self._sf_scalar = self.head_dim ** 0.5\n",
    "        # same matrix produce q,k,v\n",
    "        self.qkv = th.nn.ModuleList([th.nn.Linear(in_features=in_dim, out_features=self.head_dim*3) for _ in range(heads)])\n",
    "\n",
    "        self.lnorm = th.nn.LayerNorm(in_dim)\n",
    "        self.feed_forward = th.nn.Linear(in_features=in_dim, out_features=out_dim)\n",
    "    \n",
    "    def _dot_product_self_attention(self, head: int, x: th.Tensor, pad_mask: th.Tensor):\n",
    "        B, T, _ = x.shape\n",
    "        qkv = self.qkv[head](x) \n",
    "        \n",
    "        query, keys, vals = qkv.chunk(3, dim=-1)\n",
    "        \n",
    "        # [B. m, m]\n",
    "        e = query @ keys.mT \n",
    "        e = e.masked_fill(pad_mask.unsqueeze(1),  float('-inf'))\n",
    "        # using scalled dot product attention\n",
    "        alpha = th.softmax(e/ self._sf_scalar, dim=-1) # [B, m, m]\n",
    "        attention_pool = alpha @ vals # [B, m, d/h]\n",
    "        attention_pool = attention_pool * (~pad_mask[...,None])\n",
    "        return attention_pool\n",
    "\n",
    "    def forward(self, x: th.Tensor, pad_mask: th.Tensor):\n",
    "        # x: [B, m, d]\n",
    "        # attention: [B, m, d] where d is the concatenated d/h attention pools\n",
    "        attention = th.concat([self._dot_product_self_attention(head=i, x=x, pad_mask=pad_mask) for i in range(self.num_heads)],dim=-1)\n",
    "        # for padding tokens the the entries in x will have 0 vectors\n",
    "        resid_norm = self.lnorm(attention + x)\n",
    "        logits = self.feed_forward(resid_norm) * (~pad_mask[...,None])\n",
    "\n",
    "        return th.relu(logits)\n",
    "with th.no_grad():\n",
    "    batch = 10\n",
    "    contxt_window = 32\n",
    "    embedding_size = 8\n",
    "    out_dim = 3\n",
    "    mattn = MultiHeadAttentionBlock(in_dim=embedding_size, out_dim=out_dim,heads=2)\n",
    "    # setting right half as valid tokens and left as paddings\n",
    "    pad_mask = th.zeros(batch, contxt_window)\n",
    "    pad_mask[:, contxt_window//2:] = 1 \n",
    "    pad_mask = (pad_mask==0)\n",
    "    \n",
    "    x = th.randn(batch, contxt_window, embedding_size)\n",
    "    # make the left side 0 embedding vectors\n",
    "    x[:, :contxt_window//2, :] = 0 \n",
    "    \n",
    "    out = mattn(x,pad_mask)\n",
    "    assert out.shape == (batch, contxt_window, out_dim)\n",
    "        # left half full of zeros, right half full of values\n",
    "    assert out[:,:16,:].sum() == 0\n",
    "    assert abs(out[:,16:,:].sum()) >= 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0192d8f0-93f3-44cb-a36d-3144e2598af4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModelWithAttention(th.nn.Module):\n",
    "    def __init__(self, vocab_size: int, embedding_dim: int, hidden_dim: int, padding_idx: int, ctxt_size: int, heads:int):\n",
    "        super().__init__()\n",
    "        self._padding_id = padding_idx\n",
    "        # # initialize embeddings as on hot encoded vector + small noise\n",
    "        # noisy_onehot = th.eye(vocab_size) + (th.randn(vocab_size, vocab_size) - 0.5) * 0.033\n",
    "        self.embeddings = th.nn.Embedding(num_embeddings=vocab_size, embedding_dim=embedding_dim,padding_idx=padding_idx) #.from_pretrained(noisy_onehot, padding_idx=padding_idx)\n",
    "        self.pos_embd = th.nn.Embedding(num_embeddings=ctxt_size+1, embedding_dim=embedding_dim, padding_idx=0)\n",
    "        \n",
    "        self.attn1 = MultiHeadAttentionBlock(embedding_dim, hidden_dim, heads)\n",
    "        self.attn2 = MultiHeadAttentionBlock(hidden_dim, hidden_dim, heads)\n",
    "        \n",
    "        self.fc = th.nn.Linear(hidden_dim, vocab_size)\n",
    "        \n",
    "    def forward(self, x: th.Tensor):\n",
    "        # x: [B, seq]\n",
    "        x_embd = self.embeddings(x) # {B, seq, n]\n",
    "        pad_mask = (x == self._padding_id)\n",
    "        # [0,0,0,0,1,2,3,4..]\n",
    "        token_positions = (~pad_mask).cumsum(dim=1)\n",
    "        pos_embd = self.pos_embd(token_positions)\n",
    "        \n",
    "        x_embd += pos_embd\n",
    "        \n",
    "        attn1 = self.attn1(x_embd, pad_mask) # [B, seq, n]\n",
    "        attn_out = self.attn2(attn1, pad_mask).sum(dim=1) # [B, n]\n",
    "        return self.fc(attn_out)\n",
    "        \n",
    "with th.no_grad():\n",
    "    model = ModelWithAttention(vocab_size=10, embedding_dim=12,hidden_dim=4, padding_idx=0,ctxt_size=32, heads=4)\n",
    "    x = th.randint(0, 10, (8, 32))\n",
    "    logits = model(x)\n",
    "    assert logits.shape == (8, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1748d285-a785-49d1-ad6c-ed5adb6427cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_vars = 3\n",
    "expr_range = (2, 5)\n",
    "number_range = (-10, 10)\n",
    "float_round = 2\n",
    "sampler = ExpSentence(n_vars, expr_range, number_range, float_round, 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "126e59aa-290f-416d-952d-a218bb893474",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total: 130,486\n",
      "Trainable: 130,486\n",
      "Model size: 0.498 MB\n"
     ]
    }
   ],
   "source": [
    "embedding_dim = 64\n",
    "hidden_dim = 128\n",
    "context_window = 512 # maximum tokens that we can fit in the context\n",
    "heads = 4\n",
    "\n",
    "\n",
    "calc = ModelWithAttention(vocab_size=len(sampler.vocab), embedding_dim=embedding_dim,hidden_dim=hidden_dim, padding_idx=PADDING_TOKEN_ID,ctxt_size=context_window, heads=heads)\n",
    "\n",
    "# Total parameters\n",
    "total_params = sum(p.numel() for p in calc.parameters())\n",
    "\n",
    "# Trainable parameters only\n",
    "trainable_params = sum(p.numel() for p in calc.parameters() if p.requires_grad)\n",
    "\n",
    "print(f\"Total: {total_params:,}\")\n",
    "print(f\"Trainable: {trainable_params:,}\")\n",
    "\n",
    "param_size = 0\n",
    "for param in calc.parameters():\n",
    "    param_size += param.nelement() * param.element_size()\n",
    "    \n",
    "buffer_size = 0\n",
    "for buffer in calc.buffers():\n",
    "    buffer_size += buffer.nelement() * buffer.element_size()\n",
    "\n",
    "size_all_mb = (param_size + buffer_size) / 1024**2\n",
    "print(f\"Model size: {size_all_mb:.3f} MB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ddc06bc0-d0cf-427c-ae27-7bb9cd5cf556",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d82a9ddf414946c9a20a8bac996724aa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training Epochs:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "32ca765819ac484989000f9d384631ce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch #1:   0%|          | 0/32 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bee1a35cc454484199d1492bde15c9f5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch #2:   0%|          | 0/32 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "82334c4b4c864cb8bcd7c933f80a97f0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch #3:   0%|          | 0/32 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6eaaa77e56ea43e3b6c434738e8c785b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch #4:   0%|          | 0/32 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9f22e6864b1040b2ae7e3728eb41d334",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch #5:   0%|          | 0/32 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b60eb68365e54be194770f720cc395dd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch #6:   0%|          | 0/32 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "51d9ae994b4d4da3b06f1a3220fc656f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch #7:   0%|          | 0/32 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "15223162a94345148e0c9d761172fc57",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch #8:   0%|          | 0/32 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bf5a2946f82c40208642bb391c396302",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch #9:   0%|          | 0/32 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "646bad04a5304d818c09e0c8a18c415b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch #10:   0%|          | 0/32 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "eta = 0.001\n",
    "\n",
    "epochs = 10\n",
    "batch_size = 128\n",
    "batches_per_epoch = 32\n",
    "\n",
    "criterion = th.nn.CrossEntropyLoss(ignore_index=PADDING_TOKEN_ID)\n",
    "optimizer = th.optim.Adam(calc.parameters(), lr=eta)\n",
    "\n",
    "losses = []\n",
    "for epoch in tqdm(range(epochs), desc=\"Training Epochs\"):\n",
    "    batch_bar = tqdm(range(batches_per_epoch), desc=f\"Epoch #{epoch+1}\", leave=False)\n",
    "    for i in batch_bar:\n",
    "    \n",
    "        tgt = sampler.create_training_batch(batch_size, context_window)\n",
    "\n",
    "        # past sequence, next output\n",
    "        tgt_input = tgt[:, :-1]  \n",
    "        tgt_output = tgt[:, -1]\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        logits = calc(tgt_input)\n",
    "        \n",
    "        loss = criterion(\n",
    "            logits.reshape(-1, logits.size(-1)),\n",
    "            tgt_output\n",
    "        )\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        loss_val = loss.item()\n",
    "        losses.append(loss_val)\n",
    "        batch_bar.set_postfix(loss=f\"{loss_val:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b197c9bb-323e-4c04-a7d7-add7e9447e76",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "updates = list(range(1, len(losses)+1))\n",
    "plt.figure()\n",
    "plt.plot(updates, losses)\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.title(\"Training Loss\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f1037e08-e6a6-4546-8ea5-4524c39cc257",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample(\n",
    "    calc,\n",
    "    expr: str,\n",
    "    max_len: int = 10,\n",
    "    greedy: bool = True,\n",
    "):\n",
    "    expr_len = len(expr)\n",
    "\n",
    "    expr = [encode_expression(expr)]\n",
    "    expr[0].append( sampler.vocab[START_OF_ANSWER] )\n",
    "\n",
    "    with th.no_grad():\n",
    "          \n",
    "        for _ in range(max_len):\n",
    "            encodings = th.tensor(expr)\n",
    "            logits = calc(encodings)\n",
    "            # logits: [B, 1, vocab]\n",
    "            logits = logits.squeeze(1)\n",
    "    \n",
    "            if greedy:\n",
    "                next_token = logits.argmax(dim=-1)\n",
    "            else:\n",
    "                probs = th.softmax(logits, dim=-1)\n",
    "                next_token = th.multinomial(probs, num_samples=1).squeeze(1)\n",
    "    \n",
    "            expr[0].append(next_token.item())\n",
    "    \n",
    "            # early stop if all finished\n",
    "            if (next_token == sampler.vocab[']']).all():\n",
    "                break\n",
    "    \n",
    "    return expr[0][expr_len:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7f4bb578-b964-4685-822e-29472c9304e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "$( m ) * o * o - ( m ) / z;o=7.1,z=0.01,m=-8.11! = [402.17]\n",
      "Calc = [12.8]\n",
      "$a / ( t + ( y * a ) );y=-5.51,t=6.54,a=9.06! = [-0.21]\n",
      "Calc = [--0.44]\n",
      "$( y - ( o * u ) );o=-0.91,u=1.63,y=3.75! = [5.23]\n",
      "Calc = [-1.22]\n",
      "$( r ) - ( p + ( r ) - ( t ) * t );p=-5.21,t=0.21,r=0.78! = [5.25]\n",
      "Calc = [.33]\n",
      "$i * l * c;c=-1.57,i=-6.49,l=-9.72! = [-99.04]\n",
      "Calc = [--2.55]\n",
      "$b + g + p;b=-1.51,p=2.95,g=-7.69! = [-6.25]\n",
      "Calc = [--.9]\n",
      "$( w ) * ( l + ( c ) - w );c=-8.05,w=0.61,l=-8.64! = [-10.55]\n",
      "Calc = [.12]\n",
      "$i / f;i=1.83,f=-8.03! = [-0.23]\n",
      "Calc = [-1.1]\n",
      "$( j * z ) - z / l;z=1.65,j=0.85,l=2.43! = [0.72]\n",
      "Calc = [-1.1]\n",
      "$( l ) + ( g ) * b;b=1.51,g=8.21,l=-4.19! = [8.21]\n",
      "Calc = [-1.28]\n"
     ]
    }
   ],
   "source": [
    "for expr_sen, bp in zip(*sampler.sample(10)):\n",
    "    expr, ans = expr_sen[:bp], expr_sen[bp:]\n",
    "    result = sample(calc, expr, greedy=True)\n",
    "    predict = ''.join(decode_expression(result))\n",
    "    print(f\"{expr} = {ans}\\nCalc = {predict}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlpr (venv)",
   "language": "python",
   "name": "mlpr"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
